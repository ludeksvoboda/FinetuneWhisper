{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import torch\n",
    "import os\n",
    "from deepsparse import Engine\n",
    "\n",
    "models_dir = os.getenv(\"MODELS\")\n",
    "model_size = \"small\"\n",
    "save_dir = f\"{models_dir}/checkpoints/FinetuneWhisper/{model_size}/\"\n",
    "\n",
    "# encoder = Engine(model = save_dir + \"sparse-model_encoder.onnx\", batch_size=1)\n",
    "\n",
    "audio = whisper.load_audio(\"test_file.wav\")\n",
    "audio = whisper.pad_or_trim(audio)\n",
    "\n",
    "# make log-Mel spectrogram and move to the same device as the model\n",
    "mel = whisper.log_mel_spectrogram(audio).to('cpu')\n",
    "mel = torch.unsqueeze(mel, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_features = encoder([mel.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DeepSparse, Copyright 2021-present / Neuralmagic, Inc. version: 1.5.3 COMMUNITY | (238e86ba) (release) (optimized) (system=avx2, binary=avx2)\n"
     ]
    }
   ],
   "source": [
    "woptions = whisper.DecodingOptions(language=\"cs\", without_timestamps=True)\n",
    "encoder = Engine(model = save_dir + \"sparse-model_encoder.onnx\", batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = decoder(dec_input_ids, audio_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 80, 3000])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import decode_local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = os.getenv(\"MODELS\")\n",
    "model_size = \"small\"\n",
    "save_dir = f\"{models_dir}/checkpoints/FinetuneWhisper/{model_size}/\"\n",
    "# model_to_load = \"small_sparsify_full_data_(9).tar\"\n",
    "model_to_load = \"small_10e_full_data_(9).tar\"\n",
    "\n",
    "model = whisper.load_model(model_size, device=\"cpu\")\n",
    "\n",
    "# checkpoint = torch.load(f\"{save_dir}{model_to_load}\")\n",
    "# model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "# device = torch.device(\"cpu\")\n",
    "# model = model.eval().to(device)\n",
    "\n",
    "# model = model.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_features = model(mel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from whisper.decoding import decode\n",
    "woptions = whisper.DecodingOptions(language=\"cs\", without_timestamps=True, fp16=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Engine' object has no attribute 'dims'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m out_ds \u001b[39m=\u001b[39m decode_local\u001b[39m.\u001b[39;49mdecode(model_ds, mel, woptions)\n",
      "File \u001b[0;32m~/pythonEnvs/FinetuneWhisper/lib/python3.10/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Projects/FinetuneWhisper/decode_local.py:819\u001b[0m, in \u001b[0;36mdecode\u001b[0;34m(model, mel, options, **kwargs)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[39mif\u001b[39;00m kwargs:\n\u001b[1;32m    817\u001b[0m     options \u001b[39m=\u001b[39m replace(options, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 819\u001b[0m result \u001b[39m=\u001b[39m DecodingTask(model, options)\u001b[39m.\u001b[39mrun(mel)\n\u001b[1;32m    821\u001b[0m \u001b[39mreturn\u001b[39;00m result[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m single \u001b[39melse\u001b[39;00m result\n",
      "File \u001b[0;32m~/Projects/FinetuneWhisper/decode_local.py:523\u001b[0m, in \u001b[0;36mDecodingTask.__init__\u001b[0;34m(self, model, options)\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions: DecodingOptions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_verify_options(options)\n\u001b[1;32m    522\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_group: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m options\u001b[39m.\u001b[39mbeam_size \u001b[39mor\u001b[39;00m options\u001b[39m.\u001b[39mbest_of \u001b[39mor\u001b[39;00m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 523\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_ctx: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mdims\u001b[39m.\u001b[39mn_text_ctx\n\u001b[1;32m    524\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msample_len: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m options\u001b[39m.\u001b[39msample_len \u001b[39mor\u001b[39;00m model\u001b[39m.\u001b[39mdims\u001b[39m.\u001b[39mn_text_ctx \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39m2\u001b[39m\n\u001b[1;32m    526\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msot_sequence: Tuple[\u001b[39mint\u001b[39m] \u001b[39m=\u001b[39m tokenizer\u001b[39m.\u001b[39msot_sequence\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Engine' object has no attribute 'dims'"
     ]
    }
   ],
   "source": [
    "out_ds = decode_local.decode(model_ds, mel, woptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'deepsparse.engine.Engine'>({'onnx_file_path': '/media/storageDiskOne/Models/checkpoints/FinetuneWhisper/small/sparse-model_full.onnx', 'batch_size': 1, 'num_cores': 6, 'num_streams': 1, 'scheduler': <Scheduler.default: 'single_stream'>, 'fraction_of_supported_ops': 0.9994, 'cpu_avx_type': 'avx2', 'cpu_vnni': False})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = decode(model, mel, woptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DecodingResult(audio_features=tensor([[-4.0832e-01, -7.4131e-01, -1.0129e-01,  ..., -3.5352e+00,\n",
       "          -2.6627e-01, -9.4030e-02],\n",
       "         [-4.2037e-01,  1.8341e-01,  7.4923e-01,  ..., -3.1495e+00,\n",
       "           9.9287e-02, -5.7317e-01],\n",
       "         [ 3.0320e-01,  4.0879e-01,  4.2216e-01,  ..., -4.1880e+00,\n",
       "           3.0938e-01, -5.7166e-01],\n",
       "         ...,\n",
       "         [-2.0259e-02, -9.0696e-04,  1.1130e-02,  ...,  7.8368e-03,\n",
       "           1.2481e-02, -9.6445e-04],\n",
       "         [-1.9254e-02,  1.6439e-03,  6.7464e-03,  ...,  4.6371e-03,\n",
       "           9.6358e-03, -3.5179e-03],\n",
       "         [-1.7146e-02,  2.8349e-03,  2.2480e-03,  ...,  4.6335e-03,\n",
       "           6.0764e-03, -5.2152e-03]]), language='cs', language_probs=None, tokens=[883, 47896, 29913, 350, 3173, 2322, 281, 538, 752, 1868, 5179, 526, 11, 991, 538, 2752, 256, 15781, 68, 4231, 408, 15781, 916, 2081, 11, 25178, 899, 23241, 875, 11, 25178, 12228, 76, 361, 6712, 710, 651, 3285, 23241, 13], text='No protože kdyby to bylo frontové, tak by mi třeba neřekli, že smůla, že mám jít zase domů.', avg_logprob=-0.36457098984136815, no_speech_prob=0.04272221773862839, temperature=0.0, compression_ratio=1.01)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out #vanilla large model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DecodingResult(audio_features=tensor([[ 0.8062, -1.7990,  0.4692,  ...,  0.7749, -0.1169, -0.1896],\n",
       "         [ 2.3084, -0.0809,  0.6526,  ...,  1.5216,  0.0856,  0.7517],\n",
       "         [ 2.6287,  0.4045,  0.9158,  ...,  1.6075,  0.4498,  0.5000],\n",
       "         ...,\n",
       "         [ 0.7301, -0.2441, -0.2018,  ..., -0.4468, -0.0843, -0.4381],\n",
       "         [-0.0569, -0.6914,  0.1499,  ..., -0.7845, -0.1028,  0.0493],\n",
       "         [ 0.3543,  0.5359,  1.9167,  ...,  0.2192, -1.5670,  0.0210]]), language='cs', language_probs=None, tokens=[44, 996, 81, 8206, 538, 220, 975, 275, 9290, 1868, 875, 220, 83, 14532, 306, 2752, 220, 83, 15781, 68, 4231, 408, 15781, 916, 2081, 11, 25178, 899, 75, 425, 842, 11, 25178, 13524, 11822, 220, 1353, 369, 3285, 23241, 13], text='Mobroti by te mlad frontla takhle mi třeba neřekli, že smlulá, že mamý to se domů.', avg_logprob=-0.15973225094023205, no_speech_prob=3.374025364655253e-11, temperature=0.0, compression_ratio=0.978021978021978)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out #finetuned small model 10e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DecodingResult(audio_features=tensor([[ 0.8062, -1.7990,  0.4692,  ...,  0.7749, -0.1169, -0.1896],\n",
       "         [ 2.3084, -0.0809,  0.6526,  ...,  1.5216,  0.0856,  0.7517],\n",
       "         [ 2.6287,  0.4045,  0.9158,  ...,  1.6075,  0.4498,  0.5000],\n",
       "         ...,\n",
       "         [ 0.7301, -0.2441, -0.2018,  ..., -0.4468, -0.0843, -0.4381],\n",
       "         [-0.0569, -0.6914,  0.1499,  ..., -0.7845, -0.1028,  0.0493],\n",
       "         [ 0.3543,  0.5359,  1.9167,  ...,  0.2192, -1.5670,  0.0210]]), language='cs', language_probs=None, tokens=[376, 23241, 9159, 3498, 275, 6712, 11, 25178, 369, 281, 275, 23241, 9159, 3498, 274, 9648, 14087, 13], text='Můžete mít, že se to můžete dělat.', avg_logprob=-1.318422518278423, no_speech_prob=0.14135855436325073, temperature=0.0, compression_ratio=0.9761904761904762)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out #default small model pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DecodingResult(audio_features=tensor([[ 0.8062, -1.7990,  0.4692,  ...,  0.7749, -0.1169, -0.1896],\n",
       "         [ 2.3084, -0.0809,  0.6526,  ...,  1.5216,  0.0856,  0.7517],\n",
       "         [ 2.6287,  0.4045,  0.9158,  ...,  1.6075,  0.4498,  0.5000],\n",
       "         ...,\n",
       "         [ 0.7301, -0.2441, -0.2018,  ..., -0.4468, -0.0843, -0.4381],\n",
       "         [-0.0569, -0.6914,  0.1499,  ..., -0.7845, -0.1028,  0.0493],\n",
       "         [ 0.3543,  0.5359,  1.9167,  ...,  0.2192, -1.5670,  0.0210]]), language='cs', language_probs=None, tokens=[57, 1424, 23241, 67, 9648, 43388, 996, 31617, 220, 83, 15781, 68, 4231, 408, 15781, 916, 2081, 7891, 377, 84, 4013, 11, 25178, 42713, 1398, 2752, 220, 1353, 369, 3285, 23241, 13], text='Zprůděpodobně třeba neřeklišestuji, že jsme mi to se domů.', avg_logprob=-0.2577292124430339, no_speech_prob=2.4374387924686047e-11, temperature=0.0, compression_ratio=0.8918918918918919)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out #sparsified cpu without engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def decode(\n",
    "    model: \"Whisper\",\n",
    "    mel: Tensor,\n",
    "    options: DecodingOptions = DecodingOptions(),\n",
    "    **kwargs,\n",
    ") -> Union[DecodingResult, List[DecodingResult]]:\n",
    "    \"\"\"\n",
    "    Performs decoding of 30-second audio segment(s), provided as Mel spectrogram(s).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model: Whisper\n",
    "        the Whisper model instance\n",
    "\n",
    "    mel: torch.Tensor, shape = (80, 3000) or (*, 80, 3000)\n",
    "        A tensor containing the Mel spectrogram(s)\n",
    "\n",
    "    options: DecodingOptions\n",
    "        A dataclass that contains all necessary options for decoding 30-second segments\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result: Union[DecodingResult, List[DecodingResult]]\n",
    "        The result(s) of decoding contained in `DecodingResult` dataclass instance(s)\n",
    "    \"\"\"\n",
    "    if single := mel.ndim == 2:\n",
    "        mel = mel.unsqueeze(0)\n",
    "\n",
    "    if kwargs:\n",
    "        options = replace(options, **kwargs)\n",
    "\n",
    "    result = DecodingTask(model, options).run(mel)\n",
    "\n",
    "    return result[0] if single else result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FinetuneWhisper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
